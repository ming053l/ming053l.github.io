---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}


<span class='anchor' id='about-me'></span>

# ğŸ§â€â™‚ï¸ Biography

I received my B.S. degree in 2023 from the Department of Statistics and Information Science at Fu Jen Catholic University (FJCU), Taiwan, where I was advised by Prof. Hao-Chiang Shao. I recently completed my M.S. degree at National Cheng Kung University (NCKU), where I conducted research at the 
<a href="https://sites.google.com/view/acvlab/" style="color:#0B3C8A;">Advanced Computer Vision Laboratory (ACVLAB)</a> 
under the mentorship of Prof. 
<a href="https://cchsu.info/" style="color:#0B3C8A;">Chih-Chung Hsu</a> 
and the Computational Photography Laboratory at National Yang Ming Chiao Tung University (NYCU), working with Prof. 
<a href="https://yulunalexliu.github.io/" style="color:#0B3C8A;">Yu-Lun Liu</a>. 
I will be pursuing my Ph.D. at the University at Albany, State University of New York (SUNY), where I will continue my research collaboration with Prof. 
<a href="https://www.albany.edu/faculty/mchang2/" style="color:#0B3C8A;">Ming-Ching Chang</a>. 
Find my resume 
<a href="https://drive.google.com/file/d/1eScbrrYYBnmpGsqvjF-DXRo07L2i7evm/view?usp=sharing" 
   style="color:#0B3C8A;" 
   target="_blank">here</a> 
(last updated Jan 17, 2026).


My research interests include, but are not limited to, 
<span style="color:#0B5D1E"><b>Low-level Vision Problems</b></span>, 
<span style="color:#0B5D1E"><b>Computational Photography</b></span>, 
<span style="color:#0B5D1E"><b>Multimedia Information Security</b></span>, 
<span style="color:#0B5D1E"><b>Efficient AI</b></span>, and 
<span style="color:#0B5D1E"><b>Medical Image Analysis</b></span>. 

In my free time, I enjoy traveling âœˆï¸, capturing moments through photography ğŸ“¸, and making desserts ğŸ°.
  
# ğŸ”¥ News
- *2025/12/23*: &nbsp; I have started my military service.
- *2025/12/17*: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in WACV 2026, SkiTB Visual Tracking Challenge.
- *2025/12/3*: &nbsp;ğŸ‰ğŸ‰ I receive the 3rd performance in ICASSP 2026, Hyper-Object Challenge. See you in Barcelona.
- *2025/11/24*: &nbsp;ğŸ‰ğŸ‰ I receive the top 2% performance in BMVC 2025, Data-Centric Land Cover Classification Challenge.
- *2025/11/17*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by IJCV 2025!
- *2025/11/14*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by WACV 2026. See you in Arizona!
- *2025/10/23*: &nbsp;ğŸ‰ğŸ‰ I receive the Best Master Thesis Award in IEEE Tainan Section 2025. <a href="https://r10.ieee.org/tainan/blog/2025/10/20/2025-awards-recipients/" target="https://r10.ieee.org/tainan/blog/2025/10/20/2025-awards-recipients/">Link</a>
- *2025/09/19*: &nbsp;ğŸ‰ğŸ‰ I receive the Future Tech Awards (2025 æœªä¾†ç§‘æŠ€ç) (Top-3%).
- *2025/08/20*: &nbsp;ğŸ‰ğŸ‰ I receive the Excellent Master Thesis Award in IPPR 2025. <a href="https://ippr.org.tw/wp-content/uploads/2025/08/%E7%AC%AC18%E5%B1%86%E5%8D%9A%E7%A2%A9%E5%A3%AB%E8%AB%96%E6%96%87%E7%8D%8E%E7%8D%B2%E7%8D%8E%E5%90%8D%E5%96%AE.pdf" target="https://ippr.org.tw/wp-content/uploads/2025/08/%E7%AC%AC18%E5%B1%86%E5%8D%9A%E7%A2%A9%E5%A3%AB%E8%AB%96%E6%96%87%E7%8D%8E%E7%8D%B2%E7%8D%8E%E5%90%8D%E5%96%AE.pdf">Link</a>
- *2025/08/20*: &nbsp;ğŸ‰ğŸ‰ I receive the Best paper Awards in CVGIP 2025.
- *2025/7/24*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICCVW 2025.
- *2025/7/19*: &nbsp;ğŸ‰ğŸ‰ Three paper is accepted by ACMMM 2025.
- *2025/7/15*:: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in ACMMM 2025, SoccerTrack Challenge@MMSports.
- *2025/7/7*:: &nbsp;ğŸ‰ğŸ‰ I have successfully defended my Master's Thesis in NCKU!
- *2025/7/6*:: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in ICCV 2025, Multi-source COV19 Detection Challenge.
- *2025/6/18*: &nbsp;ğŸ‰ğŸ‰ I receive the top2% ranking in ACMMM 2025, Social Media Popularity Prediction Challenge.
- *2025/5/30*: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in ICRA 2025, TreeScope Tree Diameter Estimation Challenge.
- *2025/3/24*: &nbsp;ğŸ‰ğŸ‰ I receive the 3rd performance in CVPR 2025 (NTIRE Workshop, Image Shadow Removal Challenge).
- *2025/3/24*: &nbsp;ğŸ‰ğŸ‰ I receive the top3% ranking in CVPR 2025 (NTIRE Workshop, Image Reflection Removal Challenge).
- *2025/3/15*: &nbsp;ğŸ‰ğŸ‰ Four paper are accepted by IGARSS 2025.
- *2024/12/24*: &nbsp;ğŸ‰ğŸ‰ I receive the runner-up in USV-based Embedded Obstacle Segmentation, in conjuncted with WACV 2025.
- *2024/09/19*: &nbsp;ğŸ‰ğŸ‰ I receive the Future Tech Awards (2024 æœªä¾†ç§‘æŠ€ç). <a href="https://www.futuretech.org.tw/futuretech/index.php?action=brands_detail&br_uid=389&web_lang=en-us" target="https://www.futuretech.org.tw/futuretech/index.php?action=brands_detail&br_uid=389&web_lang=en-us">Link</a>

# ğŸ“ Selected Publications 

# ğŸ“ Selected Publications 

<div class="category-buttons" style="margin-bottom: 30px; display: flex; flex-wrap: wrap; gap: 10px; align-items: center;"> 
  <span style="font-weight: bold;">Filter by Topic:</span> 
  <a href="#restoration" class="btn btn-sm z-depth-0" style="background-color: #f1f1f1; border: 1px solid #ddd;">Image Restoration</a> 
  <a href="#hsi" class="btn btn-sm z-depth-0" style="background-color: #f1f1f1; border: 1px solid #ddd;">HSI & Remote Sensing</a> 
  <a href="#efficient" class="btn btn-sm z-depth-0" style="background-color: #f1f1f1; border: 1px solid #ddd;">Efficient AI</a> 
  <a href="#security" class="btn btn-sm z-depth-0" style="background-color: #f1f1f1; border: 1px solid #ddd;">Security & Deepfake</a> 
</div>

<h2 id="restoration" style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">âœ¨ Image Restoration & Enhancement</h2>

<div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 25px; border-bottom: 1px solid #eee; padding-bottom: 20px;">
  <div class='paper-box-image' style="flex: 0 0 250px; max-width: 100%; margin-right: 20px;">
    <div class="badge" style="position: absolute; background: red; color: white; padding: 2px 8px; font-size: 12px; border-radius: 3px;">New!</div>
    <img src='images/simflowsr.gif' alt="sym" style="width: 100%; border-radius: 5px;">
  </div>
  <div class='paper-box-text' style="flex: 1; min-width: 300px;">
    <h4 style="margin-top: 0;">SimFlowSR: Self-similarity Aggregation over Consistent Information Flow for Single Image Super-Resolution</h4>
    <p><strong>Chia-Ming Lee</strong>, Chih-Chung Hsu</p>
    <p style="font-size: 0.9em; color: #555;"><i>Keywords: Super-resolution, Information Bottleneck, Self-similarity</i></p>
    <div class="links">
      <a href="https://ming053l.github.io/SimFlowSR/" class="btn btn-sm z-depth-0" target="_blank" style="border: 1px solid #0B3C8A; padding: 2px 10px;">Project Page</a>
      <a href="https://github.com/ming053l/SimFlowSR" class="btn btn-sm z-depth-0" target="_blank" style="border: 1px solid #0B3C8A; padding: 2px 10px;">Github</a>
    </div>
  </div>
</div>

<div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 25px; border-bottom: 1px solid #eee; padding-bottom: 20px;">
  <div class='paper-box-image' style="flex: 0 0 250px; max-width: 100%; margin-right: 20px;">
    <div class="badge" style="position: absolute; background: #555; color: white; padding: 2px 8px; font-size: 12px; border-radius: 3px;">CVPRW 2024</div>
    <img src='images/drct_fix.gif' alt="sym" style="width: 100%; border-radius: 5px;">
  </div>
  <div class='paper-box-text' style="flex: 1; min-width: 300px;">
    <h4 style="margin-top: 0;">DRCT: Saving Image Super-Resolution away from Information Bottleneck</h4>
    <p>Chih-Chung Hsu, <strong>Chia-Ming Lee</strong>, Yi-Shiuan Chou</p>
    <p style="font-size: 0.9em; color: #555;"><i>Keywords: Super-resolution, Information Bottleneck</i></p>
    <div class="links">
      <a href="https://arxiv.org/abs/2404.00722" class="btn btn-sm z-depth-0" target="_blank" style="border: 1px solid #0B3C8A; padding: 2px 10px;">arXiv</a>
      <a href="https://github.com/ming053l/DRCT" class="btn btn-sm z-depth-0" target="_blank" style="border: 1px solid #0B3C8A; padding: 2px 10px;">Github</a>
    </div>
  </div>
</div>

<div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 25px; border-bottom: 1px solid #eee; padding-bottom: 20px;">
  <div class='paper-box-image' style="flex: 0 0 250px; max-width: 100%; margin-right: 20px;">
    <img src='images/PhaSR.png' style="width: 100%; border-radius: 5px;">
  </div>
  <div class='paper-box-text' style="flex: 1; min-width: 300px;">
    <h4 style="margin-top: 0;">PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors</h4>
    <p><strong>Chia-Ming Lee</strong>, Yu-Fan Lin, Yu-Jou Hsiao, Chih-Chung Hsu, Yu-Lun Liu</p>
    <p style="font-size: 0.9em; color: #555;"><i>Keywords: Shadow Removal, Physical Priors</i></p>
    <div class="links">
      <a href="https://ming053l.github.io/PhaSR/" class="btn btn-sm z-depth-0" target="_blank" style="border: 1px solid #0B3C8A; padding: 2px 10px;">Project Page</a>
    </div>
  </div>
</div>

<h2 id="hsi" style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">ğŸ›°ï¸ Hyperspectral & Remote Sensing</h2>

<div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 25px; border-bottom: 1px solid #eee; padding-bottom: 20px;">
  <div class='paper-box-image' style="flex: 0 0 250px; max-width: 100%; margin-right: 20px;">
    <div class="badge" style="position: absolute; background: #e67e22; color: white; padding: 2px 8px; font-size: 12px; border-radius: 3px;">TGRS Submitted</div>
    <img src='images/PromptHSI.png' style="width: 100%; border-radius: 5px;">
  </div>
  <div class='paper-box-text' style="flex: 1; min-width: 300px;">
    <h4 style="margin-top: 0;">PromptHSI: Universal Hyperspectral Image Restoration</h4>
    <p><strong>Chia-Ming Lee</strong>, et al.</p>
    <p style="font-size: 0.9em; color: #555;"><i>Keywords: HSI Restoration, Vision-Language Prompt</i></p>
    <div class="links">
      <a href="https://arxiv.org/abs/2411.15922" class="btn btn-sm z-depth-0" target="_blank" style="border: 1px solid #0B3C8A; padding: 2px 10px;">arXiv</a>
    </div>
  </div>
</div>

<h2 id="efficient" style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">âš¡ Efficient AI & Acceleration</h2>

<div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 25px; border-bottom: 1px solid #eee; padding-bottom: 20px;">
  <div class='paper-box-image' style="flex: 0 0 250px; max-width: 100%; margin-right: 20px;">
    <img src='images/ELSA.png' style="width: 100%; border-radius: 5px;">
  </div>
  <div class='paper-box-text' style="flex: 1; min-width: 300px;">
    <h4 style="margin-top: 0;">ELSA: Exact Linear-Scan Attention for Vision Transformers</h4>
    <p>Chih-Chung Hsu, Xin-Di Ma, Wo-Ting Liao, <strong>Chia-Ming Lee</strong></p>
    <p style="font-size: 0.9em; color: #555;"><i>Keywords: ViT Acceleration, Linear Attention</i></p>
  </div>
</div>

<h2 id="security" style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">ğŸ›¡ï¸ Multimedia Security & Deepfake Detection</h2>

<div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 25px;">
  <div class='paper-box-image' style="flex: 0 0 250px; max-width: 100%; margin-right: 20px;">
    <div class="badge" style="position: absolute; background: #27ae60; color: white; padding: 2px 8px; font-size: 12px; border-radius: 3px;">IJCV 2025</div>
    <img src='images/UMCL.png' style="width: 100%; border-radius: 5px;">
  </div>
  <div class='paper-box-text' style="flex: 1; min-width: 300px;">
    <h4 style="margin-top: 0;">UMCL: Cross-compression-rate Deepfake Detection</h4>
    <p>Ching-Yi Lai, et al.</p>
    <p style="font-size: 0.9em; color: #555;"><i>Keywords: Deepfake Detection, Contrastive Learning</i></p>
  </div>
</div>


# ğŸ– Honors and Awards

- *2025.12*:  **3rd place (3/136)**, Hyper-Object Challenge, Spectral Reconstruction from Mosaic Images, IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP).
- *2025.12*:  **3rd place (3/274)**, Hyper-Object Challenge, Joint Spatial and Spectral Super-Resolution, IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP).
- *2025.11*:  **4th place (4/418)**, Data-Centric Land Cover Classification Challenge, British Machine Vision Conference (BMVC).
- *2025.10*:  **Best Master Thesis Award**, IEEE Tainan Section 2025.
- *2025.09*:  **Future Tech Awards** (2025 æœªä¾†ç§‘æŠ€ç) (Top-3%).
- *2025.08*:  **Excellent Master Thesis Award**, IPPR 2025.
- *2025.07*:  **Winner**, SoccerTrack Challenge, Multimedia Content Analysis in Sports, ACM International Conference on Multimedia (ACMMM). 
- *2025.07*:  **Winner**, Multi-source COV19 Detection Challenge, PHAROS Adaptation, Fairness, Explainability in AI Medical Imaging Workshop, IEEE/CVF International Conference on Computer Vision (ICCV).
- *2025.06*:  **5th place (5/486)**, Social Media Popularity Prediction Challenge, ACM International Conference on Multimedia (ACMMM). 
- *2025.05*:  **Winner**, TreeScope Tree Diameter Estimation Challenge, IEEE International Conference on Robotics and Automation (ICRA).
- *2025.03*:  **6th place (6/244)**, NTIRE 2025 Single Image Reflection Removal in the Wild Challenge, IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2025.03*:  **3rd place (3/306)**, NTIRE 2025 Single Image Shadow Removal Challenge, IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2024.12*:  **Runner-up (2/700)**, USV-based Embedded Obstacle Segmentation Challenge, Maritime Computer Vision Workshop, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV).
- *2024.12*:  Shanghai Commercial and Savings Bank Foundation Scholarship.
- *2024.09*:  **Future Tech Awards** (2024 æœªä¾†ç§‘æŠ€ç).
- *2024.07*:  **Winner**, Beyond Visible Spectrum: AI for Agriculture Challenge, International Conference on Pattern Recognition (ICPR). 
- *2024.05*:  **Top Performance Award**, Socia Media Popularity Prediction Challenge, ACM International Conference on Multimedia (ACMMM). 
- *2024.03*:  9th place (9/288), AI City Challenge Track 4: Road Object Detection in Fish-Eye Cameras, IEEE Computer Vision & Pattern Recognition (CVPR). 
- *2024.03*:  **6th place (6/195)**, NTIRE 2024 Image Super-Resolution (x4), IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2024.03*:  **3rd place (3/21)**, COVID-19 Detection Challange, Domain adaptation, Explainability and Fairness in AI for Medical Image Analysis, IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2024.03*:  **Runner-up (2/1200+)**, Auto-WCEBleedGen Challenge Version V2, IEEE International Conference on Image Processing (ICIP).
- *2024.01*:  **(?/8) Ministry of Education Presidential Education Award Candicate in NCKU**.
- *2024.01*:  6th place (6/195), SeaDroneSee Multi-Object Tracking and Re-Identification Challenge, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Workshop on Maritime Computer Vision (MaCVi).
- *2023.12*:  **2nd place (2/129)**, Embedded AI Object Detection Model Design, PAIR-LITEON Competition, ACM International Conference on Multimedia Asia (MMAsia).
- *2023.11*:  **Gold Medal Award (1/150+)**, SAS Hackathon, [Reported by 6+ domsetic media].
- *2023.10*:  **Top Paper Award (3/700+)** , Socia Media Popularity Prediction Challenge, ACM International Conference on Multimedia (ACMMM).
- *2023.10*:  **Jury Prize (1/176)**, Visual Inductive Priors Workshop on Instance Segmentation Challenge, IEEE/CVF International Conference on Computer Vision (ICCV).
- *2023.06*:  **Winner (1/18)**, COV19 Detection Challenge, AI-enabled Medical Image Analysis Workshop in IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP).

# ğŸš€ Academic Services

### ğŸ“ Reviewer
- *Conference Papers*: CVPR'24, ICLR'25, CVPR'25, ICCV'25, ACMMM'25, MMAsia'25, AAAI'26, CVPR'26, ICME'26
- *Journal Papers*: TMM, TIFS, TGRS, GRSL, IJPRAI
