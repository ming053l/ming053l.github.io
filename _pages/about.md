---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}


<span class='anchor' id='about-me'></span>

# ğŸ§â€â™‚ï¸ Biography

I received my B.S. degree in 2023 from the Department of Statistics and Information Science at Fu Jen Catholic University (FJCU), Taiwan, where I was advised by Prof. Hao-Chiang Shao. I recently completed my M.S. degree at National Cheng Kung University (NCKU), where I conducted research at the 
<a href="https://sites.google.com/view/acvlab/" style="color:#0B3C8A;">Advanced Computer Vision Laboratory (ACVLAB)</a> 
under the mentorship of Prof. 
<a href="https://cchsu.info/" style="color:#0B3C8A;">Chih-Chung Hsu</a> 
and the Computational Photography Laboratory at National Yang Ming Chiao Tung University (NYCU), working with Prof. 
<a href="https://yulunalexliu.github.io/" style="color:#0B3C8A;">Yu-Lun Liu</a>. 
I will be pursuing my Ph.D. at the University at Albany, State University of New York (SUNY), where I will continue my research collaboration with Prof. 
<a href="https://www.albany.edu/faculty/mchang2/" style="color:#0B3C8A;">Ming-Ching Chang</a>. 
Find my resume 
<a href="https://drive.google.com/file/d/1eScbrrYYBnmpGsqvjF-DXRo07L2i7evm/view?usp=sharing" 
   style="color:#0B3C8A;" 
   target="_blank">here</a> 
(last updated Jan 17, 2026).


My research interests include, but are not limited to, 
<span style="color:#0B5D1E"><b>Low-level Vision Problems</b></span>, 
<span style="color:#0B5D1E"><b>Computational Photography</b></span>, 
<span style="color:#0B5D1E"><b>Hyperspectral Image Processing</b></span>, 
<span style="color:#0B5D1E"><b>Multimedia Analysis and Security</b></span>, 
<span style="color:#0B5D1E"><b>Efficient AI</b></span>, and 
<span style="color:#0B5D1E"><b>Medical Image Analysis</b></span>. 

In my free time, I enjoy traveling âœˆï¸, capturing moments through photography ğŸ“¸, and making desserts ğŸ°.
  
# ğŸ”¥ News
- *2025/12/23*: &nbsp; I have started my military service.
- *2025/12/17*: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in WACV 2026, SkiTB Visual Tracking Challenge.
- *2025/12/3*: &nbsp;ğŸ‰ğŸ‰ I receive the 3rd performance in ICASSP 2026, Hyper-Object Challenge. See you in Barcelona.
- *2025/11/24*: &nbsp;ğŸ‰ğŸ‰ I receive the top 2% performance in BMVC 2025, Data-Centric Land Cover Classification Challenge.
- *2025/11/17*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by IJCV 2025!
- *2025/11/14*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by WACV 2026. See you in Arizona!
- *2025/10/23*: &nbsp;ğŸ‰ğŸ‰ I receive the Best Master Thesis Award in IEEE Tainan Section 2025. <a href="https://r10.ieee.org/tainan/blog/2025/10/20/2025-awards-recipients/" target="https://r10.ieee.org/tainan/blog/2025/10/20/2025-awards-recipients/">Link</a>
- *2025/09/19*: &nbsp;ğŸ‰ğŸ‰ I receive the Future Tech Awards (2025 æœªä¾†ç§‘æŠ€ç) (Top-3%).
- *2025/08/20*: &nbsp;ğŸ‰ğŸ‰ I receive the Excellent Master Thesis Award in IPPR 2025. <a href="https://ippr.org.tw/wp-content/uploads/2025/08/%E7%AC%AC18%E5%B1%86%E5%8D%9A%E7%A2%A9%E5%A3%AB%E8%AB%96%E6%96%87%E7%8D%8E%E7%8D%B2%E7%8D%8E%E5%90%8D%E5%96%AE.pdf" target="https://ippr.org.tw/wp-content/uploads/2025/08/%E7%AC%AC18%E5%B1%86%E5%8D%9A%E7%A2%A9%E5%A3%AB%E8%AB%96%E6%96%87%E7%8D%8E%E7%8D%B2%E7%8D%8E%E5%90%8D%E5%96%AE.pdf">Link</a>
- *2025/08/20*: &nbsp;ğŸ‰ğŸ‰ I receive the Best paper Awards in CVGIP 2025.
- *2025/7/24*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ICCVW 2025.
- *2025/7/19*: &nbsp;ğŸ‰ğŸ‰ Three paper is accepted by ACMMM 2025.
- *2025/7/15*:: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in ACMMM 2025, SoccerTrack Challenge@MMSports.
- *2025/7/7*:: &nbsp;ğŸ‰ğŸ‰ I have successfully defended my Master's Thesis in NCKU!
- *2025/7/6*:: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in ICCV 2025, Multi-source COV19 Detection Challenge.
- *2025/6/18*: &nbsp;ğŸ‰ğŸ‰ I receive the top2% ranking in ACMMM 2025, Social Media Popularity Prediction Challenge.
- *2025/5/30*: &nbsp;ğŸ‰ğŸ‰ I receive the 1st performance in ICRA 2025, TreeScope Tree Diameter Estimation Challenge.
- *2025/3/24*: &nbsp;ğŸ‰ğŸ‰ I receive the 3rd performance in CVPR 2025 (NTIRE Workshop, Image Shadow Removal Challenge).
- *2025/3/24*: &nbsp;ğŸ‰ğŸ‰ I receive the top3% ranking in CVPR 2025 (NTIRE Workshop, Image Reflection Removal Challenge).
- *2025/3/15*: &nbsp;ğŸ‰ğŸ‰ Four paper are accepted by IGARSS 2025.
- *2024/12/24*: &nbsp;ğŸ‰ğŸ‰ I receive the runner-up in USV-based Embedded Obstacle Segmentation, in conjuncted with WACV 2025.
- *2024/09/19*: &nbsp;ğŸ‰ğŸ‰ I receive the Future Tech Awards (2024 æœªä¾†ç§‘æŠ€ç). <a href="https://www.futuretech.org.tw/futuretech/index.php?action=brands_detail&br_uid=389&web_lang=en-us" target="https://www.futuretech.org.tw/futuretech/index.php?action=brands_detail&br_uid=389&web_lang=en-us">Link</a>

# ğŸ“ Selected Publications 

<div class="category-buttons" style="margin-bottom: 30px; display: flex; flex-wrap: wrap; gap: 10px; align-items: center;"> 
  <span style="font-weight: bold;">Filter by Topic:</span> 
  
  <button onclick="filterCategory('all', event)" class="filter-btn active" style="background-color: #333; color: white; border: 1px solid #ddd; padding: 2px 12px; border-radius: 5px; cursor: pointer; font-size: 0.9em;">Show All</button> 
  
  <button onclick="filterCategory('restoration', event)" class="filter-btn" style="background-color: #f1f1f1; border: 1px solid #ddd; padding: 2px 12px; border-radius: 5px; cursor: pointer; font-size: 0.9em; color: #333;">Image Restoration</button> 
  
  <button onclick="filterCategory('hsi', event)" class="filter-btn" style="background-color: #f1f1f1; border: 1px solid #ddd; padding: 2px 12px; border-radius: 5px; cursor: pointer; font-size: 0.9em; color: #333;">HSI & Remote Sensing</button> 
  
  <button onclick="filterCategory('efficient', event)" class="filter-btn" style="background-color: #f1f1f1; border: 1px solid #ddd; padding: 2px 12px; border-radius: 5px; cursor: pointer; font-size: 0.9em; color: #333;">Efficient AI</button> 
  
  <button onclick="filterCategory('security', event)" class="filter-btn" style="background-color: #f1f1f1; border: 1px solid #ddd; padding: 2px 12px; border-radius: 5px; cursor: pointer; font-size: 0.9em; color: #333;">Security & Deepfake</button> 
</div>

<div id="section-restoration" class="category-section">
  <h2 style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">âœ¨ Image Restoration & Enhancement</h2>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px; position: relative;">
      <div style="position: absolute; background: #c0392b; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">New!</div>
      <img src='images/simflowsr.gif' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">SimFlowSR: Self-similarity Aggregation over Consistent Information Flow for Single Image Super-Resolution</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><strong>Chia-Ming Lee</strong>, <a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Image Super-resolution (Stronger, faster DRCT)</li>
        <li>Information Bottleneck & Self-similarity Aggregation</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://ming053l.github.io/SimFlowSR/" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Project Page</a>
        <a href="https://github.com/ming053l/SimFlowSR" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Github</a>
      </div>
    </div>
  </div>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px; position: relative;">
      <div style="position: absolute; background: #0B3C8A; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">CVPRW2024</div>
      <img src='images/drct_fix.gif' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">DRCT: Saving Image Super-Resolution away from Information Bottleneck</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a>, <strong>Chia-Ming Lee</strong>, <a href="https://nelly0421.github.io/" target="_blank" style="text-decoration: underline;">Yi-Shiuan Chou</a></p>
      <div style="margin-bottom: 10px; display: flex; align-items: center; gap: 8px;">
        <span style="font-weight: bold;">Keywords</span>
        <img src="https://img.shields.io/github/stars/ming053l/DRCT?style=social" alt="Github Stars">
      </div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Image Super-resolution</li>
        <li>Information Bottleneck</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://arxiv.org/pdf/2404.00722.pdf" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">PDF</a>
        <a href="https://arxiv.org/abs/2404.00722" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">arxiv</a>
        <a href="https://github.com/ming053l/DRCT" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Github</a>
        <a href="https://allproj002.github.io/drct.github.io/" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Project page</a>
        <a href="https://drive.google.com/file/d/1zR9wSwqCryLeKVkJfTuoQILKiQdf_Vdz/view?usp=sharing" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Poster</a>
        <a href="https://docs.google.com/presentation/d/1MxPPtgQZ61GFSr3YfGOm9scm23bbbXRj/edit?usp=sharing" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Slide</a>
      </div>
    </div>
  </div>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px;">
      <img src='images/PhaSR.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><strong>Chia-Ming Lee</strong>, <a href="https://vanlinlin.github.io/" target="_blank" style="text-decoration: underline;">Yu-Fan Lin</a>, Yu-Jou Hsiao, Jing-Hui Jung, <a href="https://yulunalexliu.github.io/" target="_blank" style="text-decoration: underline;">Yu-Lun Liu</a>, <a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Single Image Shadow Removal</li>
        <li>Ambient Light Normalization</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://ming053l.github.io/PhaSR/" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Project Page</a>
      </div>
    </div>
  </div>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px;">
      <img src='images/ReflexSplit.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">ReflexSplit: Single Image Reflection Separation via Layer Fusionâ€“Separation</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><strong>Chia-Ming Lee</strong>, <a href="https://vanlinlin.github.io/" target="_blank" style="text-decoration: underline;">Yu-Fan Lin</a>, Jing-Hui Jung, Yu-Jou Hsiao, <a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a>, <a href="https://yulunalexliu.github.io/" target="_blank" style="text-decoration: underline;">Yu-Lun Liu</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Single Reflection Removal</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://wuw2135.github.io/ReflexSplit-ProjectPage/" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Project Page</a>
      </div>
    </div>
  </div>
</div>

<div id="section-hsi" class="category-section">
  <h2 style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">ğŸ›°ï¸ Hyperspectral & Remote Sensing</h2>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px; position: relative;">
      <div style="position: absolute; background: #e67e22; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">Submitted to TGRS</div>
      <img src='images/PromptHSI.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">PromptHSI: Universal Hyperspectral Image Restoration with Vision-Language Modulated Frequency Adaptation</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><strong>Chia-Ming Lee</strong>, Ching-Heng Cheng, <a href="https://vanlinlin.github.io/" target="_blank" style="text-decoration: underline;">Yu-Fan Lin</a>, Yi-Ching Cheng, Wo-Ting Liao, <a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a>, <a href="https://fuenyang1127.github.io/" target="_blank" style="text-decoration: underline;">Fu-En Yang</a>, <a href="https://vllab.ee.ntu.edu.tw/ycwang.html" target="_blank" style="text-decoration: underline;">Yu-Chiang Frank Wang</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Hyperspectral Image Restoration & Text-Prompt Learning</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://arxiv.org/abs/2411.15922" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">arxiv</a>
        <a href="https://github.com/chingheng0808/PromptHSI" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Github</a>
        <a href="https://drive.google.com/drive/folders/1O0GDzoPt3AVD4mjXeu3R_lxyuTDEWWW1" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">Dataset</a>
      </div>
    </div>
  </div>
</div>

<div id="section-efficient" class="category-section">
  <h2 style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">âš¡ Efficient AI & Acceleration</h2>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px;">
      <div style="position: absolute; background: #27ae60; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">Under Review</div>
      <img src='images/ELSA.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">ELSA: Exact Linear-Scan Attention for Fast and Memory-Light Vision Transformers</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a>, Xin-Di Ma, Wo-Ting Liao, <strong>Chia-Ming Lee</strong></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Hardware-Agnositic Transformer Acceleration</li>
        <li>Exact Linear-Scan Attention</li>
      </ul>
    </div>
  </div>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px;">
      <div style="position: absolute; background: #27ae60; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">Under Review</div>
      <img src='images/FracQuant.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">FracQuant: Fractal Complexity Assessment for Content-aware Image Super-resolution Network Quantization</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><strong>Chia-Ming Lee</strong>, Yu-Fan Lin, <a href="https://fuenyang1127.github.io/" target="https://fuenyang1127.github.io/">Fu-En Yang</a>, <a href="https://vllab.ee.ntu.edu.tw/ycwang.html" target="https://vllab.ee.ntu.edu.tw/ycwang.html">Yu-Chiang Frank Wang</a>, <a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Fractal Coding for Image Compression</li>
        <li>Network Compression and Quantization</li>
      </ul>
    </div>
  </div>
</div>

<div id="section-security" class="category-section">
  <h2 style="clear: both; border-bottom: 2px solid #0B3C8A; padding-bottom: 10px; margin-top: 50px;">ğŸ›¡ï¸ Multimedia Analysis and Security</h2>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px; position: relative;">
      <div style="position: absolute; background: #27ae60; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">IJCV 2026</div>
      <img src='images/UMCL.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">UMCL: Unimodal-generated Multimodal Constrative Learning for Cross-compression-rate Deepfake Detection</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;">Ching-Yi Lai, Chih-Yu Jian, Pei-Cheng Chuang, <strong>Chia-Ming Lee</strong>, <a href="https://cchsu.info/" target="_blank" style="text-decoration: underline;">Chih-Chung Hsu</a>, <a href="https://www.cs.nthu.edu.tw/~cthsu/candy.html" target="_blank" style="text-decoration: underline;">Chiou-Ting Hsu</a>, <a href="https://www.ee.nthu.edu.tw/cwlin/" target="_blank" style="text-decoration: underline;">Chia-Wen Lin</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Multimodality Constrative Learning</li>
        <li>Robust DeepFake Detection</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://arxiv.org/abs/2511.18983" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">arxiv</a>
      </div>
    </div>

  <div class='paper-box' style="display: flex; flex-wrap: wrap; margin-bottom: 35px; align-items: flex-start;">
    <div class='paper-box-image' style="flex: 0 0 350px; max-width: 100%; margin-right: 25px; position: relative;">
      <div style="position: absolute; background: #27ae60; color: white; padding: 2px 10px; font-size: 13px; font-weight: bold; top: 10px; left: 0px; z-index: 1;">Submitted to TIFS</div>
      <img src='images/GRACEv2.png' style="width: 100%; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); border-radius: 2px;">
    </div>
    <div class='paper-box-text' style="flex: 1; min-width: 300px;">
      <h4 style="margin: 0 0 10px 0; font-size: 1.15em; color: #333;">Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior</h4>
      <p style="margin: 0 0 10px 0; font-size: 1.05em;"><a href="https://cchsu.info/" target="https://cchsu.info/">Chih-Chung Hsu</a>, Shao-Ning Chen, Mei-Hsuan Wu, **Chia-Ming Lee**, Yi-Fang Wang, <a href="https://nelly0421.github.io/" target="https://nelly0421.github.io/">Yi-Shiuan Chou</a></p>
      <div style="margin-bottom: 5px; font-weight: bold;">Keywords</div>
      <ul style="margin: 0 0 15px 20px; padding: 0; color: #555;">
        <li>Adversarial Attack</li>
        <li>Graph Convolutional Network</li>
        <li>Robust DeepFake Detection</li>
      </ul>
      <div class="links" style="display: flex; flex-wrap: wrap; gap: 6px;">
        <a href="https://arxiv.org/abs/2511.18983" target="_blank" style="background: #7a838b; color: white; padding: 5px 15px; border-radius: 4px; font-size: 0.9em; font-weight: bold; text-decoration: none;">arxiv</a>
      </div>
    </div>
  </div>
</div>

# ğŸ– Honors and Awards

- *2025.12*:  **3rd place (3/136)**, Hyper-Object Challenge, Spectral Reconstruction from Mosaic Images, IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP).
- *2025.12*:  **3rd place (3/274)**, Hyper-Object Challenge, Joint Spatial and Spectral Super-Resolution, IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP).
- *2025.11*:  **4th place (4/418)**, Data-Centric Land Cover Classification Challenge, British Machine Vision Conference (BMVC).
- *2025.10*:  **Best Master Thesis Award**, IEEE Tainan Section 2025.
- *2025.09*:  **Future Tech Awards** (2025 æœªä¾†ç§‘æŠ€ç) (Top-3%).
- *2025.08*:  **Excellent Master Thesis Award**, IPPR 2025.
- *2025.07*:  **Winner**, SoccerTrack Challenge, Multimedia Content Analysis in Sports, ACM International Conference on Multimedia (ACMMM). 
- *2025.07*:  **Winner**, Multi-source COV19 Detection Challenge, PHAROS Adaptation, Fairness, Explainability in AI Medical Imaging Workshop, IEEE/CVF International Conference on Computer Vision (ICCV).
- *2025.06*:  **5th place (5/486)**, Social Media Popularity Prediction Challenge, ACM International Conference on Multimedia (ACMMM). 
- *2025.05*:  **Winner**, TreeScope Tree Diameter Estimation Challenge, IEEE International Conference on Robotics and Automation (ICRA).
- *2025.03*:  **6th place (6/244)**, NTIRE 2025 Single Image Reflection Removal in the Wild Challenge, IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2025.03*:  **3rd place (3/306)**, NTIRE 2025 Single Image Shadow Removal Challenge, IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2024.12*:  **Runner-up (2/700)**, USV-based Embedded Obstacle Segmentation Challenge, Maritime Computer Vision Workshop, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV).
- *2024.12*:  Shanghai Commercial and Savings Bank Foundation Scholarship.
- *2024.09*:  **Future Tech Awards** (2024 æœªä¾†ç§‘æŠ€ç).
- *2024.07*:  **Winner**, Beyond Visible Spectrum: AI for Agriculture Challenge, International Conference on Pattern Recognition (ICPR). 
- *2024.05*:  **Top Performance Award**, Socia Media Popularity Prediction Challenge, ACM International Conference on Multimedia (ACMMM). 
- *2024.03*:  9th place (9/288), AI City Challenge Track 4: Road Object Detection in Fish-Eye Cameras, IEEE Computer Vision & Pattern Recognition (CVPR). 
- *2024.03*:  **6th place (6/195)**, NTIRE 2024 Image Super-Resolution (x4), IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2024.03*:  **3rd place (3/21)**, COVID-19 Detection Challange, Domain adaptation, Explainability and Fairness in AI for Medical Image Analysis, IEEE/CVF Computer Vision & Pattern Recognition (CVPR). 
- *2024.03*:  **Runner-up (2/1200+)**, Auto-WCEBleedGen Challenge Version V2, IEEE International Conference on Image Processing (ICIP).
- *2024.01*:  **(?/8) Ministry of Education Presidential Education Award Candicate in NCKU**.
- *2024.01*:  6th place (6/195), SeaDroneSee Multi-Object Tracking and Re-Identification Challenge, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Workshop on Maritime Computer Vision (MaCVi).
- *2023.12*:  **2nd place (2/129)**, Embedded AI Object Detection Model Design, PAIR-LITEON Competition, ACM International Conference on Multimedia Asia (MMAsia).
- *2023.11*:  **Gold Medal Award (1/150+)**, SAS Hackathon, [Reported by 6+ domsetic media].
- *2023.10*:  **Top Paper Award (3/700+)** , Socia Media Popularity Prediction Challenge, ACM International Conference on Multimedia (ACMMM).
- *2023.10*:  **Jury Prize (1/176)**, Visual Inductive Priors Workshop on Instance Segmentation Challenge, IEEE/CVF International Conference on Computer Vision (ICCV).
- *2023.06*:  **Winner (1/18)**, COV19 Detection Challenge, AI-enabled Medical Image Analysis Workshop in IEEE International Conference on Acoustics, Speech, & Signal Processing (ICASSP).

# ğŸš€ Academic Services

### ğŸ“ Reviewer
- *Conference Papers*: CVPR'24, ICLR'25, CVPR'25, ICCV'25, ACMMM'25, MMAsia'25, AAAI'26, CVPR'26, ICME'26
- *Journal Papers*: TMM, TIFS, TGRS, GRSL, IJPRAI


<script>
function filterCategory(categoryId, e) {
  // é˜²æ­¢ä»»ä½•é€£çµè·³è½‰è¡Œç‚º
  if (e) e.preventDefault();

  // 1. å–å¾—æ‰€æœ‰é¡åˆ¥å€å¡Š
  const sections = document.querySelectorAll('.category-section');
  
  sections.forEach(section => {
    if (categoryId === 'all') {
      section.style.display = 'block';
    } else {
      if (section.id === 'section-' + categoryId) {
        section.style.display = 'block';
      } else {
        section.style.display = 'none';
      }
    }
  });

  // 2. æ›´æ–°æŒ‰éˆ•æ¨£å¼
  const buttons = document.querySelectorAll('.category-buttons button');
  buttons.forEach(btn => {
    btn.style.backgroundColor = '#f1f1f1';
    btn.style.color = '#333';
  });
  
  // é«˜äº®ç•¶å‰é»æ“Šçš„æŒ‰éˆ•
  if (e && e.currentTarget) {
    e.currentTarget.style.backgroundColor = '#333';
    e.currentTarget.style.color = 'white';
  }
}
</script>
